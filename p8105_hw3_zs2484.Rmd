---
title: "Homework 3 solutions"
author: "Zichen Shu"
output: github_document

---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)



theme_set(theme_minimal() + theme(legend.position = "botton"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_color_viridis_d
```

### Problem 1

```{r}
data("instacart")

```

The dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

How many aisles, and which are most item from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Let's make a plot

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apples vs ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


### Problem 2

```{r, warning = FALSE}
accel_data = 
  read.csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(activity_1:activity_1440, 
               names_to = "minute", 
               names_prefix = "activity_", 
               values_to = "activity_count") %>%
  mutate(
    weekday_vs_weekend = case_when(day == "Monday" ~ "weekday", day == "Tuesday" ~ "weekday", day == "Wednesday" ~ "weekday", day == "Thursday" ~ "weekday", day == "Friday" ~ "weekday", day == "Saturday" ~ "weekend",day == "Sunday" ~ "weekend"),
    day = forcats::fct_relevel(day, c("Monday","Tuesday","Wednesday","Thursday", "Friday", "Saturday","Sunday")),
    minute = as.double(minute))
  
```

The raw datset is in "wide" format. I used `pivot_longer` to transform the dataset into "long", tidy and workable format. And I also created a weekday vs weeknd variable. In the end, the resulting dataset contains **`r names(accel_data)`** variables. It **`r nrow(accel_data)`** rows and **`r ncol(accel_data)`** columns while each column is an observation.


```{r, message = FALSE}
accel_data %>% 
  group_by(week, day) %>% 
  summarize(activity_day = sum(activity_count)) %>% 
  pivot_wider(names_from = week, values_from = activity_day) %>% 
  knitr::kable(digits = 1)
```

I created 7X5 table showing the daily activity account for five weeks for that person. The person had a high activity count on first Sunday and low count on the fourth and last Saturday. Otherwise, there is no apparent trend.


```{r, fig.width = 8, fig.height = 8}
accel_data %>% 
  ggplot(aes(x = minute, y = activity_count, group = day_id)) +
  geom_line(aes(colour = day))
```

```{r, message = FALSE, fig.width = 8, fig.height = 8}
accel_data_hour = 
  accel_data %>% 
  mutate(hour = (minute - 1) %/%60) %>% 
  group_by(day_id, day, hour) %>% 
  summarize(hour_activity = sum(activity_count))

accel_data_hour %>% 
  ggplot(aes(x = hour, y = hour_activity, group = day_id)) +
  geom_line(aes(colour = day ))

```

I created a 24-hour activity time course plot for each day by minute. The graph has lots of noise and hard to read. So, I made a 24-hour activity time course plot for each day by hour. It shows two peaks roughly around 10am and 8pm and lower activity counts elsewhere.


### Problem 3

```{r}
data("ny_noaa")

ny_noaa = ny_noaa %>%  
  separate(date, c("year", "month", "day")) %>% 
  mutate(across(year:tmin,as.numeric),
         tmax = tmax / 10,
         tmin = tmin / 10)

ny_noaa %>% 
  group_by(snow) %>% 
  summarize(n_obs = n())%>% 
  mutate(rank  = min_rank(desc(n_obs)))

```

The New York weather dataset contains **`r names(ny_noaa)`** variables. It **`r nrow(ny_noaa)`** rows and **`r ncol(ny_noaa)`** columns while each column is an observation. The most commonly observed values for snowfall is **0**. This makes sense since most days in New York do not snow.


```{r, message = FALSE, fig.width = 8, fig.height = 8}
jan_plot =
  ny_noaa %>% 
  filter(month == 1) %>% 
  group_by(year, id) %>% 
  summarize(avg_tmax = mean(tmax)) %>% 
  drop_na() %>% 
  mutate(rank  = min_rank(desc(avg_tmax))) %>% 
  ggplot(aes(x = year, y = avg_tmax, color = id)) + 
  geom_point() +
  geom_path(alpha = 0.5)+
  theme(legend.position = 'none')+
  labs(title = "Average Maximum Temperature for Each Sationin January from 1981-2010", x = "Year", y = "Average Max Temp")

july_plot = 
  ny_noaa %>% 
  filter(month == 7) %>% 
  group_by(year, id) %>% 
  summarize(avg_tmax = mean(tmax)) %>% 
  drop_na() %>% 
  mutate(rank  = min_rank(desc(avg_tmax))) %>% 
  ggplot(aes(x = year, y = avg_tmax, color = id)) + 
  geom_point() +
  geom_path(alpha = 0.5)+
  theme(legend.position = 'none')+
  labs(title = "Average Maximum Temperature for Each Sationin July from 1981-2010", x = "Year", y = "Average Max Temp")

jan_plot / july_plot
```

The average highest temperature in January in New York is between -10 and 10 degrees celsius while it fluctuates between 20 to 35 degrees.

```{r, warning = FALSE, fig.width = 8, fig.height = 8}
tmax_tmin_plt = 
  ny_noaa %>% 
  ggplot(aes(x = tmin, y = tmax, color = id)) +
  geom_hex()+
  theme(legend.position = "none")

snowfall_plt =
  ny_noaa %>%
  filter(between(snow,0,100), !is.na(snow)) %>% 
  ggplot(aes(x = year)) +
  geom_violin(aes(y = snow, group = as.factor(year), alpha = 0.2)) +
  theme( axis.text.x = element_text(angle = 90, vjust = 0.5, size = 8, hjust = 1)) +
  scale_y_continuous(trans = "log", breaks = c(5, 15,40, 100))+
  scale_x_continuous(breaks = seq(1981,2010,1))

tmax_tmin_plt / snowfall_plt
```






